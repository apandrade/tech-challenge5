# POS FIAP ALURA - IA PARA DEVS - Tech Challenge Fase 5

## Integrantes Grupo 26

- Andr√© Philipe Oliveira de Andrade(RM357002) - andrepoandrade@gmail.com
- Joir Neto (RM356391) - joirneto@gmail.com
- Marcos Jen San Hsie(RM357422) - marcosjsh@gmail.com
- Michael dos Santos Silva(RM357009) - michael.shel96@gmail.com
- Sonival dos Santos(RM356905) - sonival.santos@gmail.com

Video(Youtube): 

Github: https://github.com/apandrade/tech-challenge5

# üß† Por que escolhemos o YOLOv8 para detec√ß√£o de objetos cortantes?

## üìå Modelos considerados

Antes de definir o modelo ideal para a detec√ß√£o de objetos cortantes, avaliamos as seguintes abordagens:

- **YOLOv8**: Modelo de detec√ß√£o supervisionada de √∫ltima gera√ß√£o, altamente eficiente para tarefas em tempo real. Suporta treinamento com classes customizadas e imagens negativas. Ideal para aplica√ß√µes pr√°ticas com recursos computacionais limitados.

- **CLIP (Contrastive Language‚ÄìImage Pretraining)**: Modelo multimodal treinado pela OpenAI que associa imagens e textos. Excelente para buscas conceituais e classifica√ß√£o zero-shot, mas n√£o √© projetado para detectar m√∫ltiplos objetos com precis√£o espacial.

- **SAM (Segment Anything Model)**: Segmentador universal da Meta AI capaz de isolar qualquer objeto em uma imagem sem necessidade de treinamento. Precisa ser combinado com modelos classificadores (como CLIP) para atribuir r√≥tulos √†s regi√µes segmentadas.

- **Florence2**: Modelo multimodal avan√ßado da Microsoft, capaz de executar diversas tarefas de vis√£o computacional. Potente e preciso, mas muito mais complexo e pesado, exigindo infraestrutura robusta.

---

## ‚öñÔ∏è Comparativo entre modelos

| Modelo/Ferramenta      | Tipo                     | Pr√≥s                                                                 | Contras                                                             | Ideal para...                                |
|------------------------|--------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------|------------------------------------------------|
| **YOLOv8**             | Detec√ß√£o supervisionada  | R√°pido, leve, f√°cil de treinar, √≥timo suporte a imagens customizadas | Requer dataset anotado                                             | Casos pr√°ticos, v√≠deos em tempo real          |
| **CLIP + Segmenta√ß√£o** | Vis√£o multimodal         | Entende texto e imagem, bom para zero-shot                           | N√£o √© ideal para detec√ß√£o precisa de m√∫ltiplos objetos              | Busca conceitual ou filtragem sem anota√ß√µes   |
| **SAM (Segment Anything)** | Segmenta√ß√£o autom√°tica | Segmenta√ß√£o precisa de qualquer objeto                               | N√£o classifica; precisa de CLIP ou labels externos                 | Separar regi√µes de interesse                  |
| **Florence2**          | Modelo multimodal avan√ßado | Potente, multitarefa, bom para contextos complexos                   | Muito pesado e complexo de usar em setups simples                   | Pesquisas, an√°lise sem√¢ntica multimodal       |
| **YOLOv5/YOLOv4**      | Detec√ß√£o supervisionada  | Bons modelos anteriores, ainda populares                             | YOLOv8 √© mais preciso e mais r√°pido                                 | Ambientes legados ou compara√ß√µes hist√≥ricas   |

---

## üß¨ Comparativo entre variantes do YOLOv8

| Variante      | Par√¢metros | Tamanho do Modelo | Velocidade (FPS) | Precis√£o (mAP@0.5) | Ideal para...                  |
|---------------|------------|-------------------|------------------|--------------------|-------------------------------|
| **YOLOv8n**   | ~3.2M      | ü™∂ Muito leve       | üöÄ Muito r√°pida   | M√©dia              | Edge, mobile, infer√™ncia leve |
| **YOLOv8s**   | ~11.2M     | üß© Leve             | üöÄ R√°pida         | Alta               | Colab, desktop, tempo real     |
| **YOLOv8m**   | ~25.9M     | ‚öñÔ∏è M√©dia            | ‚ö° Boa            | Muito Alta         | Servidores, GPUs maiores       |
| **YOLOv8l/x** | 50M+       | üèãÔ∏è‚Äç‚ôÇÔ∏è Pesado         | Mais lento        | Excelente           | Infraestrutura robusta         |

---

## üéØ Justificativa para o uso do **YOLOv8s**

Escolhemos a vers√£o **YOLOv8s** por oferecer o **melhor equil√≠brio entre desempenho e leveza**:

- ‚úÖ R√°pido o suficiente para aplica√ß√µes em tempo real, como v√≠deo e stream.
- ‚úÖ Mais preciso que o `YOLOv8n` e significativamente menor que `YOLOv8m`, o que facilita o uso no **Google Colab com GPU T4**.
- ‚úÖ Ideal para datasets customizados e com estrat√©gias de data augmentation, como o nosso (com foco em detec√ß√£o de objetos cortantes).
- ‚úÖ Suporte excelente a m√∫ltiplas inst√¢ncias e classes com bom tempo de infer√™ncia.

---

## ‚úÖ Resumo da escolha

O **YOLOv8s** foi selecionado como a arquitetura ideal por ser uma solu√ß√£o **leve, r√°pida e precisa**, perfeita para cen√°rios com **recursos computacionais limitados** e necessidade de **detec√ß√£o confi√°vel em tempo real**.

Modelos mais pesados como `YOLOv8m` ou ferramentas como `Florence2` s√£o poderosos, mas desnecess√°rios e ineficientes para o objetivo atual. O YOLOv8s entrega **√≥timo desempenho com excelente custo-benef√≠cio computacional**.


# Montagem do dataset


## üß© Montagem e Unifica√ß√£o do Dataset de Objetos Cortantes

Para garantir um bom desempenho do modelo YOLOv8 mesmo em ambientes com recursos computacionais limitados, foi necess√°rio dedicar um pouco mais de esfor√ßo √† montagem de um **dataset pequeno, mas com boa qualidade e diversidade**. A ideia foi garantir representatividade visual com varia√ß√µes de **√¢ngulo, ilumina√ß√£o, contexto e tipos de objetos cortantes**, sem sobrecarregar o processo de treinamento.

---

## üîç Por que usar o Roboflow?

A ferramenta [Roboflow](https://roboflow.com/) foi escolhida por v√°rios motivos:

- ‚úÖ Disponibilidade de **diversos datasets rotulados** de forma p√∫blica e gratuita
- ‚úÖ Interface pr√°tica para **pr√©-visualiza√ß√£o**, **filtragem por classe** e **download no formato YOLOv8**
- ‚úÖ Suporte para **datasets por vers√£o**, mantendo controle das origens
- ‚úÖ Facilidade de exporta√ß√£o padronizada (`images/` e `labels/` por split)

---

### üì• 1. Coleta dos Datasets

Realizou-se uma **pesquisa ativa por conjuntos de dados p√∫blicos no Roboflow**, com foco nas seguintes classes:

```python
["knife", "scissor", "scalpel", "axe", "saw", "chainsaw", "chisel", "sickle"]
```

Cada classe foi buscada individualmente, selecionando projetos com imagens reais, bounding boxes precisos e varia√ß√µes visuais significativas. Os datasets foram ent√£o baixados e organizados em pastas separadas por classe.

---

### üß© 2. Unifica√ß√£o dos Datasets

Como os datasets coletados possu√≠am diferentes **estruturas e √≠ndices de classes**, tornou-se necess√°rio unific√°-los.

Para isso, foi utilizado o script `unificar-dataset-e-atualizar-indice.py`, presente na pasta `scripts-utilitarios`, que:

- üóÉÔ∏è Agrupa todos os arquivos em uma estrutura comum (`test/images`, `train/images`, `valid/images`)
- üîÑ Atualiza os arquivos de r√≥tulo `.txt` para refletirem os **√≠ndices padronizados**

Essa etapa garante que os dados estejam **prontos para o treinamento em YOLOv8**, com consist√™ncia entre `data.yaml`, as imagens e os r√≥tulos.

---

### ‚úÇÔ∏è 3. Subsampling durante a unifica√ß√£o

Durante o processo de unifica√ß√£o, foi aplicado um **subsampling** para limitar a quantidade de exemplos das categorias knife e axe:

- üîÅ **M√°ximo de 1.000 imagens para as categorias alvo**
- üéØ Isso evita sobrecarregar a mem√≥ria e acelera o processo de treinamento
- ‚öñÔ∏è Ajuda a **balancear o dataset**, evitando que uma classe como `"knife"` e `"axe"` domine o aprendizado

---

#### Resultado do Subsampling

##### üìÇ Train
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 1000           |
| scissor      | 560            |
| scalpel      | 588            |
| axe          | 1000           |
| saw          | 633            |
| chainsaw     | 757            |
| chisel       | 309            |
| sickle       | 345            |

##### üìÇ Valid
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 468            |
| scissor      | 160            |
| scalpel      | 166            |
| axe          | 234            |
| saw          | 0              |
| chainsaw     | 217            |
| chisel       | 29             |
| sickle       | 0              |

##### üìÇ Test
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 127            |
| scissor      | 80             |
| scalpel      | 86             |
| axe          | 250            |
| saw          | 0              |
| chainsaw     | 106            |
| chisel       | 15             |
| sickle       | 0              |



# üß™ Superaugmenta√ß√£o de Dados com Albumentations para YOLOv8

Aplicamos t√©cnicas avan√ßadas de **data augmentation** para resolver o desequil√≠brio entre as categorias do nosso dataset de detec√ß√£o de objetos cortantes.

## üéØ Objetivo

Aumentar o n√∫mero de imagens para classes minorit√°rias como `sickle`, `chisel`, `scalpel` e `chainsaw`, garantindo que cada classe tivesse pelo menos **1000 imagens no conjunto de treino**, para manter o equil√≠brio.

---

## üß∞ T√©cnicas utilizadas

Aumenta√ß√µes aplicadas usando [Albumentations](https://albumentations.ai/), uma das bibliotecas mais r√°pidas e flex√≠veis para vis√£o computacional.

### üîÑ Transforma√ß≈çes aplicadas:

- `HorizontalFlip`: espelhamento horizontal aleat√≥rio
- `RandomBrightnessContrast`: varia√ß√£o aleat√≥ria de brilho e contraste
- `MotionBlur`: simula borr√µes de movimento
- `Affine`: rota√ß√£o, escala e deslocamento espacial
- `CoarseDropout`: t√©cnica inspirada no Cutout, simula obstru√ß√µes parciais

### ‚öôÔ∏è Par√¢metros de seguran√ßa

- `clip=True`: impede que bboxes ultrapassem os limites da imagem
- `filter_invalid_bboxes=True`: remove bboxes com √°rea inv√°lida ou posi√ß√£o negativa
- `min_visibility=0.1`: ignora bboxes com menos de 10% visibilidade ap√≥s augmenta√ß√£o

---

## üß† Problemas que resolvemos

| Problema                                   | Solu√ß√£o aplicada                                  |
|--------------------------------------------|--------------------------------------------------|
| Desequil√≠brio entre classes                | Augmenta√ß√µes direcionadas para classes minorit√°rias |
| Bounding boxes inv√°lidas ou corrompidas    | Clipping, filtro por visibilidade e checagem de validade |
| Dataset dominado por `knife` e `axe`       | Limitamos manualmente para 1000 imagens por classe |

---

## üî¢ Controle de quantidade por classe

Durante o processo de augmenta√ß√£o, adicionamos l√≥gica para:
- Contabilizar imagens por classe
- Interromper a gera√ß√£o quando a classe atingir 1000 imagens
- Permitir m√∫ltiplas classes por imagem, desde que ao menos uma esteja abaixo do limite

---

## ‚úÖ Resultado da Superaugmenta√ß√£o

Ap√≥s a aplica√ß√£o da superaugmenta√ß√£o e controle de limites, o dataset ficou assim:

### üìÇ Train
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 1000           |
| scissor      | 1560           |
| scalpel      | 1588           |
| axe          | 1000           |
| saw          | 1633           |
| chainsaw     | 1757           |
| chisel       | 1218           |
| sickle       | 1345           |

### üìÇ Valid
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 468            |
| scissor      | 160            |
| scalpel      | 166            |
| axe          | 234            |
| saw          | 0              |
| chainsaw     | 217            |
| chisel       | 29             |
| sickle       | 0              |

### üìÇ Test
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 127            |
| scissor      | 80             |
| scalpel      | 86             |
| axe          | 250            |
| saw          | 0              |
| chainsaw     | 106            |
| chisel       | 15             |
| sickle       | 0              |

---

# ‚öñÔ∏è Rebalanceamento dos Conjuntos `valid` e `test` do Dataset

Ap√≥s a aplica√ß√£o de superaugmenta√ß√µes para balancear o conjunto de treino (`train`), foi necess√°rio **rebalancear os conjuntos de valida√ß√£o (`valid`) e teste (`test`)** para garantir que todas as categorias fossem representadas adequadamente em todas as fases do treinamento.

---

## üéØ Objetivo

- Garantir que **todas as classes relevantes** estejam presentes em `valid` e `test`
- Aplicar uma divis√£o pr√≥xima a:
  - **8%** do total para `valid`
  - **4%** do total para `test`
- **Evitar desbalanceamento extremo**, especialmente em classes minorit√°rias como `saw`, `chisel` e `sickle`

---

## üîç Diagn√≥stico inicial

Antes do rebalanceamento, as seguintes classes estavam **zeradas ou sub-representadas**:

| Classe   | Train | Valid | Test |
|----------|-------|-------|------|
| saw      | 1633  | 0     | 0    |
| chisel   | 1218  | 29    | 15   |
| sickle   | 1345  | 0     | 0    |

---

## üõ†Ô∏è Estrat√©gia aplicada

Utilizamos um script para:

1. **Identificar imagens** em `train` que continham as classes 4 (saw), 6 (chisel) e 7 (sickle)
2. **Selecionar aleatoriamente**:
   - 8% das imagens ‚Üí mover para `valid`
   - 4% das imagens ‚Üí mover para `test`
3. **Mover** os arquivos de imagem (`.jpg`) e seus respectivos r√≥tulos (`.txt`)
4. Criar as pastas necess√°rias caso ainda n√£o existissem

---

## ‚úÖ Quantidades redistribu√≠das

| Classe   | Movidos para `valid` | Movidos para `test` |
|----------|----------------------|----------------------|
| saw      | 130                  | 65                   |
| chisel   | 97                   | 48                   |
| sickle   | 108                  | 54                   |

---

## üìÇ Resultado

Ap√≥s o rebalanceamento, as tr√™s classes agora tamb√©m est√£o presentes nos conjuntos `valid` e `test`, tornando a valida√ß√£o mais justa e representativa.

- Esse rebalanceamento n√£o altera o conte√∫do de treino, apenas melhora a **avalia√ß√£o final do modelo**.
- A abordagem √© **segura e eficiente**, pois evita duplica√ß√µes e mant√©m o alinhamento entre `images/` e `labels/`.
- Esse processo pode ser repetido sempre que o conjunto de treino for expandido ou alterado.

### üì∏ Quantidade de imagens por categoria e por split

#### üìÇ Train
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 1000           |
| scissor      | 1560           |
| scalpel      | 1588           |
| axe          | 1000           |
| saw          | 1438           |
| chainsaw     | 1757           |
| chisel       | 1073           |
| sickle       | 1183           |

#### üìÇ Valid
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 468            |
| scissor      | 160            |
| scalpel      | 166            |
| axe          | 234            |
| saw          | 130            |
| chainsaw     | 217            |
| chisel       | 126            |
| sickle       | 108            |

#### üìÇ Test
| Categoria    | Imagens √∫nicas |
|--------------|----------------|
| knife        | 127            |
| scissor      | 80             |
| scalpel      | 86             |
| axe          | 250            |
| saw          | 65             |
| chainsaw     | 106            |
| chisel       | 63             |
| sickle       | 54             |


## üèãÔ∏è‚Äç‚ôÇÔ∏è Treinamento

```python
model.train(
    data='/content/drive/dataset/data.yaml',
    epochs=100,
    imgsz=640,
    batch=32,
    device=0,
    workers=2,
    name='sharped-vs-nonsharped-v1',
    pretrained=True,
    augment=True,
    mosaic=1.0,
    mixup=0.2,
    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,
    flipud=0.3, fliplr=0.5,
    degrees=10.0, translate=0.1, scale=0.5, shear=2.0,
    patience=20
)
```

### ‚úÖ Par√¢metros explicados:

| Par√¢metro         | Significado                                                                 |
|------------------|-----------------------------------------------------------------------------|
| `data`           | Caminho para o arquivo `data.yaml` com caminhos e nomes das classes         |
| `epochs`         | N√∫mero m√°ximo de √©pocas de treinamento                                      |
| `imgsz`          | Tamanho da imagem (redimensionamento para 640x640)                          |
| `batch`          | Tamanho do batch (quantidade de imagens por itera√ß√£o)                      |
| `device`         | GPU a ser usada (`0` para a primeira GPU dispon√≠vel)                        |
| `workers`        | N√∫mero de workers para carregar dados em paralelo                           |
| `name`           | Nome do experimento (usado para salvar logs, pesos e m√©tricas)              |
| `pretrained`     | Usa pesos pr√©-treinados do COCO (se `True`)                                 |
| `augment`        | Ativa augmenta√ß√µes b√°sicas (como flips e mudan√ßas de brilho/contraste)      |
| `mosaic`         | Ativa **Mosaic augmentation** (1.0 = 100% das imagens usam mosaic)          |
| `mixup`          | Ativa **MixUp augmentation** com 20% de intensidade                         |
| `hsv_h/s/v`      | Varia√ß√µes de tonalidade, satura√ß√£o e brilho                                 |
| `flipud`         | Probabilidade de flip vertical                                              |
| `fliplr`         | Probabilidade de flip horizontal                                            |
| `degrees`        | Rota√ß√£o aleat√≥ria de at√© ¬±10¬∞                                               |
| `translate`      | Transla√ß√£o aleat√≥ria de at√© 10%                                             |
| `scale`          | Escala aleat√≥ria de at√© ¬±50%                                                |
| `shear`          | Inclina√ß√£o aleat√≥ria de at√© 2¬∞                                              |
| `patience`       | N√∫mero de √©pocas sem melhoria antes do Early Stopping                       |

---

## üéØ Objetivo do modelo

Detectar objetos cortantes vs. n√£o cortantes, usando imagens balanceadas, com m√∫ltiplas classes (como `knife`, `scissor`, `axe`, `sickle`, `chair`, `bathtub`, etc.) agrupadas em categorias `Sharped` e `Not-Sharped`.



